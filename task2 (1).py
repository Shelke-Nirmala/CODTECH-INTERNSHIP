# -*- coding: utf-8 -*-
"""Task2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mjYE4iOWOHC2H99GrpBfJKyGnoitmaib
"""

# Install necessary libraries
!pip install pandas scikit-learn matplotlib seaborn

# Import libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from sklearn.feature_selection import SelectKBest, f_classif

# Load dataset (Iris dataset from UCI)
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data"
columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']

# Load the dataset into a DataFrame
data = pd.read_csv(url, header=None, names=columns)

# Display first few rows of the dataset
print(data.head())

# Data Preprocessing: Convert categorical target column (species) to numerical labels
from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
data['species'] = encoder.fit_transform(data['species'])

# Split dataset into features (X) and target variable (y)
X = data.drop('species', axis=1)
y = data['species']

# Split dataset into features (X) and target variable (y)
X = data.drop('species', axis=1)
y = data['species']

# Feature Selection: Using SelectKBest to select top 2 features
selector = SelectKBest(f_classif, k=2)
X_selected = selector.fit_transform(X, y)

# Show the selected features
selected_columns = X.columns[selector.get_support()]
print(f"Selected Features: {selected_columns}")

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)

# Feature Scaling: Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

"""# Model Training: Train different machine learning models

"""

# 1. Logistic Regression
lr_model = LogisticRegression()
lr_model.fit(X_train, y_train)
lr_y_pred = lr_model.predict(X_test)

# 2. Random Forest Classifier
rf_model = RandomForestClassifier()
rf_model.fit(X_train, y_train)
rf_y_pred = rf_model.predict(X_test)

# 3. Support Vector Machine
svm_model = SVC()
svm_model.fit(X_train, y_train)
svm_y_pred = svm_model.predict(X_test)

# Evaluate the models: Accuracy and Classification Report
print("\nLogistic Regression:")
print(f"Accuracy: {accuracy_score(y_test, lr_y_pred)}")
print(classification_report(y_test, lr_y_pred))

print("\nRandom Forest Classifier:")
print(f"Accuracy: {accuracy_score(y_test, rf_y_pred)}")
print(classification_report(y_test, rf_y_pred))

print("\nSupport Vector Machine:")
print(f"Accuracy: {accuracy_score(y_test, svm_y_pred)}")
print(classification_report(y_test, svm_y_pred))

# Confusion Matrix for Random Forest Classifier (as an example)
conf_matrix = confusion_matrix(y_test, rf_y_pred)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=encoder.classes_, yticklabels=encoder.classes_)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix - Random Forest Classifier')
plt.show()